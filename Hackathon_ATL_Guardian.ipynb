{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAGdn0WFv6jaz8VMcIJkru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameerdewan/DecentralizedHousingMarket/blob/master/Hackathon_ATL_Guardian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests opencv-python opencv-python-headless numpy pytz supervision inference"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n4ZWZQELSGof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8c388DqSBrU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import signal\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import pytz\n",
        "import supervision as sv\n",
        "from inference import get_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuration\n",
        "IMAGE_URL = 'https://webcams.nyctmc.org/api/cameras/04e09ed5-2d97-4e29-8438-b87748850dbb/image'  # Replace with your image URL\n",
        "FRAME_RATE = 1  # frames per second\n",
        "VIDEO_SIZE = (640, 480)  # Set your desired video size\n",
        "OUTPUT_FILE = \"annotated_timelapse.mp4\"\n",
        "\n",
        "# Initialize model\n",
        "model = get_model(model_id=\"yolov8n-640\")\n",
        "\n",
        "def process_image(image_url):\n",
        "    # Perform inference\n",
        "    results = model.infer(\n",
        "        image=image_url,\n",
        "        confidence=0.1,\n",
        "        iou_threshold=0.1\n",
        "    )\n",
        "\n",
        "    print(results)\n",
        "\n",
        "    detections = results[0].predictions\n",
        "\n",
        "    # Fetch the image to annotate\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        response.raw.decode_content = True\n",
        "        image = np.asarray(bytearray(response.raw.read()), dtype=\"uint8\")\n",
        "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    else:\n",
        "        print(f\"Failed to fetch image for annotation. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Annotate frame\n",
        "    for det in detections:\n",
        "        x1 = int(det.x - det.width / 2)\n",
        "        y1 = int(det.y - det.height / 2)\n",
        "        x2 = int(det.x + det.width / 2)\n",
        "        y2 = int(det.y + det.height / 2)\n",
        "        label = f\"{det.class_name}: {det.confidence:.2f}\"\n",
        "        color = (0, 255, 0)  # Green color for bounding box\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "def setup_video_writer(filename, size, fps):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    writer = cv2.VideoWriter(filename, fourcc, fps, size)\n",
        "    return writer\n",
        "\n",
        "def setup_signal_handler(writer):\n",
        "    def signal_handler(sig, frame):\n",
        "        writer.release()\n",
        "        sys.exit(0)\n",
        "\n",
        "    signal.signal(signal.SIGINT, signal_handler)\n",
        "\n",
        "def display_image(image):\n",
        "    # Convert the image from BGR to RGB format\n",
        "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')  # Turn off axis labels\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    writer = setup_video_writer(OUTPUT_FILE, VIDEO_SIZE, FRAME_RATE)\n",
        "    setup_signal_handler(writer)\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # Process the image URL directly\n",
        "            annotated_image = process_image(IMAGE_URL)\n",
        "\n",
        "            if annotated_image is not None:\n",
        "                # Resize the image to match video size\n",
        "                annotated_image = cv2.resize(annotated_image, VIDEO_SIZE)\n",
        "\n",
        "                # Write the frame to the video file\n",
        "                writer.write(annotated_image)\n",
        "\n",
        "                # Display the image\n",
        "                display_image(annotated_image)\n",
        "\n",
        "            # Wait for the next frame\n",
        "            time.sleep(1 / FRAME_RATE)\n",
        "    finally:\n",
        "        writer.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}