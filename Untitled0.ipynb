{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameerdewan/DecentralizedHousingMarket/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests opencv-python opencv-python-headless numpy pytz supervision inference"
      ],
      "metadata": {
        "id": "n4ZWZQELSGof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8c388DqSBrU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import signal\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import pytz\n",
        "import supervision as sv\n",
        "from inference import get_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuration\n",
        "IMAGE_URL = 'https://webcams.nyctmc.org/api/cameras/04e09ed5-2d97-4e29-8438-b87748850dbb/image'\n",
        "FRAME_RATE = .5\n",
        "VIDEO_SIZE = (640, 480)\n",
        "OUTPUT_FILE = \"annotated_timelapse.mp4\"\n",
        "\n",
        "# Initialize model\n",
        "model = get_model(model_id=\"yolov8n-640\")\n",
        "\n",
        "# Initialize data collection\n",
        "detection_data = {\n",
        "    'timestamp': [],\n",
        "    'person': [],\n",
        "    'car': [],\n",
        "    'bus': [],\n",
        "    'truck': [],\n",
        "    'motorcycle': [],\n",
        "    'bike': []\n",
        "}\n",
        "\n",
        "def process_image(image_url):\n",
        "    # Perform inference\n",
        "    results = model.infer(\n",
        "        image=image_url,\n",
        "        confidence=0.1,\n",
        "        iou_threshold=.5\n",
        "    )\n",
        "\n",
        "    detections = results[0].predictions\n",
        "\n",
        "    # Filter detections for vehicles or people\n",
        "    valid_classes = {'person', 'car', 'bus', 'truck', 'motorcycle', 'bike'}\n",
        "    filtered_detections = [det for det in detections if det.class_name in valid_classes]\n",
        "\n",
        "    # Fetch the image to annotate\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        response.raw.decode_content = True\n",
        "        image = np.asarray(bytearray(response.raw.read()), dtype=\"uint8\")\n",
        "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    else:\n",
        "        print(f\"Failed to fetch image for annotation. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Annotate frame\n",
        "    for det in filtered_detections:\n",
        "        x1 = int(det.x - det.width / 2)\n",
        "        y1 = int(det.y - det.height / 2)\n",
        "        x2 = int(det.x + det.width / 2)\n",
        "        y2 = int(det.y + det.height / 2)\n",
        "        label = f\"{det.class_name}: {det.confidence:.2f}\"\n",
        "        if det.class_name == 'person':\n",
        "            color = (0, 0, 255)  # Red color for people\n",
        "        else:\n",
        "            color = (0, 255, 0)  # Green color for vehicles\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image, filtered_detections\n",
        "\n",
        "def setup_video_writer(filename, size, fps):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    writer = cv2.VideoWriter(filename, fourcc, fps, size)\n",
        "    return writer\n",
        "\n",
        "def setup_signal_handler(writer):\n",
        "    def signal_handler(sig, frame):\n",
        "        writer.release()\n",
        "        sys.exit(0)\n",
        "\n",
        "    signal.signal(signal.SIGINT, signal_handler)\n",
        "\n",
        "def print_detection_data(detection_data):\n",
        "    print(\"\\nCurrent Detection Data:\")\n",
        "    header = \"{:<30} {:<10} {:<10} {:<10} {:<10} {:<15} {:<10}\".format(\n",
        "        \"Timestamp\", \"Person\", \"Car\", \"Bus\", \"Truck\", \"Motorcycle\", \"Bike\"\n",
        "    )\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    for i in range(len(detection_data['timestamp'])):\n",
        "        row = \"{:<30} {:<10} {:<10} {:<10} {:<10} {:<15} {:<10}\".format(\n",
        "            detection_data['timestamp'][i].astimezone(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            detection_data['person'][i],\n",
        "            detection_data['car'][i],\n",
        "            detection_data['bus'][i],\n",
        "            detection_data['truck'][i],\n",
        "            detection_data['motorcycle'][i],\n",
        "            detection_data['bike'][i]\n",
        "        )\n",
        "        print(row)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def main():\n",
        "    writer = setup_video_writer(OUTPUT_FILE, VIDEO_SIZE, FRAME_RATE)\n",
        "    setup_signal_handler(writer)\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # Process the image URL directly\n",
        "            annotated_image, detections = process_image(IMAGE_URL)\n",
        "\n",
        "            if annotated_image is not None:\n",
        "                # Resize the image to match video size\n",
        "                annotated_image = cv2.resize(annotated_image, VIDEO_SIZE)\n",
        "\n",
        "                # Write the frame to the video file\n",
        "                writer.write(annotated_image)\n",
        "\n",
        "                # Collect data for the detected objects\n",
        "                timestamp = datetime.now(pytz.utc)\n",
        "                detection_data['timestamp'].append(timestamp)\n",
        "                detection_data['person'].append(sum(1 for det in detections if det.class_name == 'person'))\n",
        "                detection_data['car'].append(sum(1 for det in detections if det.class_name == 'car'))\n",
        "                detection_data['bus'].append(sum(1 for det in detections if det.class_name == 'bus'))\n",
        "                detection_data['truck'].append(sum(1 for det in detections if det.class_name == 'truck'))\n",
        "                detection_data['motorcycle'].append(sum(1 for det in detections if det.class_name == 'motorcycle'))\n",
        "                detection_data['bike'].append(sum(1 for det in detections if det.class_name == 'bike'))\n",
        "\n",
        "                # Print the current detection data for debugging\n",
        "                print_detection_data(detection_data)\n",
        "\n",
        "            # Wait for the next frame\n",
        "            time.sleep(1 / FRAME_RATE)\n",
        "    finally:\n",
        "        writer.release()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}