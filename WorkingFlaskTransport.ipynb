{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameerdewan/DecentralizedHousingMarket/blob/master/WorkingFlaskTransport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests opencv-python opencv-python-headless numpy pytz supervision inference flask pyngrok"
      ],
      "metadata": {
        "collapsed": true,
        "id": "n4ZWZQELSGof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8c388DqSBrU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import signal\n",
        "import sys\n",
        "import time\n",
        "from datetime import datetime\n",
        "import threading\n",
        "import cv2\n",
        "import numpy as np\n",
        "import requests\n",
        "import pytz\n",
        "import supervision as sv\n",
        "from inference import get_model\n",
        "import matplotlib.pyplot as plt\n",
        "from flask import Flask, Response, jsonify, send_file\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Configuration\n",
        "IMAGE_URL = 'https://webcams.nyctmc.org/api/cameras/04e09ed5-2d97-4e29-8438-b87748850dbb/image'\n",
        "FRAME_RATE = .5\n",
        "VIDEO_SIZE = (640, 480)\n",
        "OUTPUT_IMAGE = \"annotated_image.jpg\"\n",
        "NGROK_AUTHTOKEN = \"2hqxnQqMdvTNdeJpBd7G5OgRlIs_4x1G5iRf4bHwWLk9CZQFk\"\n",
        "NGROK_PORT = 5000\n",
        "\n",
        "# Initialize model\n",
        "model = get_model(model_id=\"yolov8n-640\")\n",
        "\n",
        "# Initialize data collection\n",
        "detection_data = {\n",
        "    'timestamp': [],\n",
        "    'person': [],\n",
        "    'car': [],\n",
        "    'bus': [],\n",
        "    'truck': [],\n",
        "    'motorcycle': [],\n",
        "    'bike': []\n",
        "}\n",
        "\n",
        "def process_image(image_url):\n",
        "    # Perform inference\n",
        "    results = model.infer(\n",
        "        image=image_url,\n",
        "        confidence=0.1,\n",
        "        iou_threshold=.5\n",
        "    )\n",
        "\n",
        "    detections = results[0].predictions\n",
        "\n",
        "    # Filter detections for vehicles or people\n",
        "    valid_classes = {'person', 'car', 'bus', 'truck', 'motorcycle', 'bike'}\n",
        "    filtered_detections = [det for det in detections if det.class_name in valid_classes]\n",
        "\n",
        "    # Fetch the image to annotate\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        response.raw.decode_content = True\n",
        "        image = np.asarray(bytearray(response.raw.read()), dtype=\"uint8\")\n",
        "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "    else:\n",
        "        print(f\"Failed to fetch image for annotation. Status code: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    # Annotate frame\n",
        "    for det in filtered_detections:\n",
        "        x1 = int(det.x - det.width / 2)\n",
        "        y1 = int(det.y - det.height / 2)\n",
        "        x2 = int(det.x + det.width / 2)\n",
        "        y2 = int(det.y + det.height / 2)\n",
        "        label = f\"{det.class_name}: {det.confidence:.2f}\"\n",
        "        if det.class_name == 'person':\n",
        "            color = (0, 0, 255)  # Red color for people\n",
        "        else:\n",
        "            color = (0, 255, 0)  # Green color for vehicles\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return image, filtered_detections\n",
        "\n",
        "def setup_signal_handler():\n",
        "    def signal_handler(sig, frame):\n",
        "        sys.exit(0)\n",
        "\n",
        "    signal.signal(signal.SIGINT, signal_handler)\n",
        "\n",
        "def print_detection_data(detection_data):\n",
        "    print(\"\\nCurrent Detection Data:\")\n",
        "    header = \"{:<30} {:<10} {:<10} {:<10} {:<10} {:<15} {:<10}\".format(\n",
        "        \"Timestamp\", \"Person\", \"Car\", \"Bus\", \"Truck\", \"Motorcycle\", \"Bike\"\n",
        "    )\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    for i in range(len(detection_data['timestamp'])):\n",
        "        row = \"{:<30} {:<10} {:<10} {:<10} {:<10} {:<15} {:<10}\".format(\n",
        "            detection_data['timestamp'][i].astimezone(pytz.timezone('US/Eastern')).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            detection_data['person'][i],\n",
        "            detection_data['car'][i],\n",
        "            detection_data['bus'][i],\n",
        "            detection_data['truck'][i],\n",
        "            detection_data['motorcycle'][i],\n",
        "            detection_data['bike'][i]\n",
        "        )\n",
        "        print(row)\n",
        "    print(\"\\n\")\n",
        "\n",
        "def main():\n",
        "    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "    public_url = ngrok.connect(NGROK_PORT).public_url\n",
        "    print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{NGROK_PORT}\\\"\")\n",
        "\n",
        "    setup_signal_handler()\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # Process the image URL directly\n",
        "            annotated_image, detections = process_image(IMAGE_URL)\n",
        "\n",
        "            if annotated_image is not None:\n",
        "                # Resize the image to match the desired size\n",
        "                annotated_image = cv2.resize(annotated_image, VIDEO_SIZE)\n",
        "\n",
        "                # Save the annotated image\n",
        "                cv2.imwrite(OUTPUT_IMAGE, annotated_image)\n",
        "\n",
        "                # Collect data for the detected objects\n",
        "                timestamp = datetime.now(pytz.utc)\n",
        "                detection_data['timestamp'].append(timestamp)\n",
        "                detection_data['person'].append(sum(1 for det in detections if det.class_name == 'person'))\n",
        "                detection_data['car'].append(sum(1 for det in detections if det.class_name == 'car'))\n",
        "                detection_data['bus'].append(sum(1 for det in detections if det.class_name == 'bus'))\n",
        "                detection_data['truck'].append(sum(1 for det in detections if det.class_name == 'truck'))\n",
        "                detection_data['motorcycle'].append(sum(1 for det in detections if det.class_name == 'motorcycle'))\n",
        "                detection_data['bike'].append(sum(1 for det in detections if det.class_name == 'bike'))\n",
        "\n",
        "                # Print the current detection data for debugging\n",
        "                print_detection_data(detection_data)\n",
        "\n",
        "            # Wait for the next frame\n",
        "            time.sleep(1 / FRAME_RATE)\n",
        "    finally:\n",
        "        ngrok.disconnect(public_url)\n",
        "\n",
        "# Flask App\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/detection_data', methods=['GET'])\n",
        "def get_detection_data():\n",
        "    return jsonify(detection_data)\n",
        "\n",
        "@app.route('/annotated_image')\n",
        "def annotated_image():\n",
        "    return send_file(OUTPUT_IMAGE, mimetype='image/jpeg')\n",
        "\n",
        "def run_flask():\n",
        "    app.run(port=NGROK_PORT, use_reloader=False)\n",
        "\n",
        "# Start the Flask app in a separate thread\n",
        "threading.Thread(target=run_flask).start()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}